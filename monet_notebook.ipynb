{"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"papermill":{"duration":3295.767085,"end_time":"2020-08-29T09:21:52.609073","environment_variables":{},"exception":null,"input_path":"__notebook__.ipynb","output_path":"__notebook__.ipynb","parameters":{},"start_time":"2020-08-29T08:26:56.841988","version":"2.1.0"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":21755,"databundleVersionId":1475600,"sourceType":"competition"}],"dockerImageVersionId":30587,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Iâ€™m Something of a Painter Myself\n\nIn this project I explore with Generative AI to convert photos to Monet styled paintings. I chose to experiment with the CycleGAN architecture after seeing it's performance on the leaderboards.","metadata":{"papermill":{"duration":0.013215,"end_time":"2020-08-29T08:27:01.892915","exception":false,"start_time":"2020-08-29T08:27:01.879700","status":"completed"},"tags":[]}},{"cell_type":"code","source":"import tensorflow as tf\nimport keras\nfrom keras import Sequential\n\nfrom tensorflow import keras\nfrom tensorflow.keras import layers, Sequential, regularizers\nimport tensorflow_addons as tfa\n\nfrom kaggle_datasets import KaggleDatasets\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport PIL\nimport os\n\npath = KaggleDatasets().get_gcs_path()\n\nmonet_files = tf.io.gfile.glob(str(path)+\"/monet_tfrec/*.tfrec\")\nphoto_files = tf.io.gfile.glob(str(path)+\"/photo_tfrec/*.tfrec\")\n\nstrategy = tf.distribute.get_strategy()\nAUTOTUNE = tf.data.experimental.AUTOTUNE\n\nprint(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))","metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","papermill":{"duration":10.623182,"end_time":"2020-08-29T08:27:12.529697","exception":false,"start_time":"2020-08-29T08:27:01.906515","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-12-11T03:07:30.103426Z","iopub.execute_input":"2023-12-11T03:07:30.103808Z","iopub.status.idle":"2023-12-11T03:07:30.109682Z","shell.execute_reply.started":"2023-12-11T03:07:30.103779Z","shell.execute_reply":"2023-12-11T03:07:30.108608Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Normalize and Parse Data","metadata":{}},{"cell_type":"code","source":"image_dimensions = (256, 256)\n\ndef normalize_image(img):\n    decoded_img = tf.io.decode_jpeg(img)\n    normalized_img = (tf.cast(decoded_img, tf.float32) / 127.5) - 1\n    reshaped_img = tf.reshape(normalized_img, [*image_dimensions, 3])\n    return reshaped_img\n\ndef extract_image(img):\n    tfrecord_format = {\n        \"image_name\": tf.io.FixedLenFeature([], tf.string),\n        \"image\": tf.io.FixedLenFeature([], tf.string),\n        \"target\": tf.io.FixedLenFeature([], tf.string)\n    }\n    parsed_img = tf.io.parse_single_example(img, tfrecord_format)\n    output = normalize_image(parsed_img[\"image\"])\n    return output\n\ndef load_dataset(filenames):#, labeled=True, ordered=False):\n    dataset = tf.data.TFRecordDataset(filenames) # creates a tfrecord dataset from the files\n    dataset = dataset.map(extract_image, num_parallel_calls=AUTOTUNE)\n    return dataset","metadata":{"execution":{"iopub.status.busy":"2023-12-11T02:36:54.089492Z","iopub.execute_input":"2023-12-11T02:36:54.090238Z","iopub.status.idle":"2023-12-11T02:36:54.098390Z","shell.execute_reply.started":"2023-12-11T02:36:54.090200Z","shell.execute_reply":"2023-12-11T02:36:54.097351Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"monet_ds = load_dataset(monet_files).batch(1)\nphoto_ds = load_dataset(photo_files).batch(1)\n\nexample_monet = next(iter(monet_ds)) \nexample_photo = next(iter(photo_ds))\n\nplt.subplot(121)\nplt.title('Photo')\nplt.imshow(example_photo[0] * 0.5 + 0.5)\n\nplt.subplot(122)\nplt.title('Monet')\nplt.imshow(example_monet[0] * 0.5 + 0.5)","metadata":{"execution":{"iopub.status.busy":"2023-12-11T02:36:54.100961Z","iopub.execute_input":"2023-12-11T02:36:54.101342Z","iopub.status.idle":"2023-12-11T02:36:59.079360Z","shell.execute_reply.started":"2023-12-11T02:36:54.101306Z","shell.execute_reply":"2023-12-11T02:36:59.078388Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"l2_lambda = 0.01\n\ndef downsample(filter_size, kernel_size, strides, padding=\"valid\", normalize=False, zeropadding=False):\n    kernel_initializer = tf.random_normal_initializer(0, 0.02)\n    gamma_initializer = keras.initializers.RandomNormal(0, 0.02)\n    \n    model = Sequential()\n\n    model.add(layers.Conv2D(filter_size, kernel_size, strides, padding=padding, kernel_regularizer=regularizers.l2(l2_lambda)))\n        \n    if normalize:\n        model.add(tfa.layers.InstanceNormalization(gamma_initializer=gamma_initializer))\n\n    if zeropadding:       \n        model.add(layers.ZeroPadding2D())\n    \n    model.add(layers.LeakyReLU())\n    return model\n\n\ndef upsample(filter_size, kernel_size, strides, padding=\"valid\", normalize=False, dropout=False, dropout_rate=0.5):\n    kernel_initializer = tf.random_normal_initializer(0, 0.02)\n    gamma_initializer = keras.initializers.RandomNormal(0, 0.02)\n    \n    model = Sequential()\n\n    model.add(layers.Conv2DTranspose(filter_size, kernel_size, strides, padding=padding, kernel_regularizer=regularizers.l2(l2_lambda)))\n    \n    if normalize:\n        model.add(tfa.layers.InstanceNormalization(gamma_initializer=gamma_initializer))\n        \n    if dropout:\n        model.add(layers.Dropout(dropout_rate))\n    \n    model.add(layers.LeakyReLU())\n    return model","metadata":{"execution":{"iopub.status.busy":"2023-12-11T02:36:59.080451Z","iopub.execute_input":"2023-12-11T02:36:59.080715Z","iopub.status.idle":"2023-12-11T02:36:59.090468Z","shell.execute_reply.started":"2023-12-11T02:36:59.080693Z","shell.execute_reply":"2023-12-11T02:36:59.089488Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"parameters = {\n    \"down\": {\"filter_size\":[64, 64, 128, 128, 256, 256, 512, 512], \"kernel_size\": [(3,3), (3,3), (3,3), (3,3), (3,3), (3,3), (3,3), (3,3)], \"strides\": [(2,2), (2,2), (2,2), (2,2), (2,2), (2,2), (2,2), (2,2)], \"padding\": [\"same\", \"same\", \"same\", \"same\", \"same\", \"same\", \"same\", \"same\"]},\n    \"up\": {\"filter_size\":[512, 512, 256, 256, 128, 128, 64, 64], \"kernel_size\": [(3,3), (3,3), (3,3), (3,3), (3,3), (3,3), (3,3), (3,3)], \"strides\": [(2,2), (2,2), (2,2), (2,2), (2,2), (2,2), (2,2), (2,2)], \"padding\": [\"same\", \"same\", \"same\", \"same\", \"same\", \"same\", \"same\", \"same\"]}\n}","metadata":{"execution":{"iopub.status.busy":"2023-12-11T02:36:59.091766Z","iopub.execute_input":"2023-12-11T02:36:59.092582Z","iopub.status.idle":"2023-12-11T02:36:59.106011Z","shell.execute_reply.started":"2023-12-11T02:36:59.092536Z","shell.execute_reply":"2023-12-11T02:36:59.105059Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def create_downsample_pipeline(n:int, parameters:dict, zeropadding, normalize):\n    downsample_pipeline = []\n    for i in range(n):\n        downsample_pipeline.append(downsample(filter_size=parameters[\"filter_size\"][i], kernel_size=parameters[\"kernel_size\"][i], strides=parameters[\"strides\"][i], padding=parameters[\"padding\"][i], normalize=normalize, zeropadding=zeropadding))\n    return downsample_pipeline\n\n\ndef create_upsample_pipeline(n:int, parameters:dict, n_dropouts:int, normalize):\n    upsample_pipeline = []\n    for i in range(n):\n        if n_dropouts >= 1:\n            upsample_pipeline.append(upsample(parameters[\"filter_size\"][i], parameters[\"kernel_size\"][i], parameters[\"strides\"][i], parameters[\"padding\"][i], dropout=True, normalize=normalize))\n            n_dropouts -= 1\n        elif n_dropouts < 1:   \n            upsample_pipeline.append(upsample(parameters[\"filter_size\"][i], parameters[\"kernel_size\"][i], parameters[\"strides\"][i], parameters[\"padding\"][i], normalize=normalize))\n    return upsample_pipeline","metadata":{"execution":{"iopub.status.busy":"2023-12-11T02:36:59.107167Z","iopub.execute_input":"2023-12-11T02:36:59.107465Z","iopub.status.idle":"2023-12-11T02:36:59.117653Z","shell.execute_reply.started":"2023-12-11T02:36:59.107441Z","shell.execute_reply":"2023-12-11T02:36:59.116802Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def Generator(n, downsample_parameters:dict, upsample_parameters:dict, n_dropouts, normalize, zeropadding):\n    inputs=layers.Input(shape=[256, 256, 3])\n    kernel_initializer=tf.random_normal_initializer(0, 0.02)\n    \n    downsample_pipeline = create_downsample_pipeline(n=n, parameters=parameters[\"down\"], zeropadding=zeropadding, normalize=normalize)\n    upsample_pipeline = create_upsample_pipeline(n=n, parameters=parameters[\"up\"], n_dropouts=n_dropouts, normalize=normalize)\n    \n    skips = []\n    x=inputs\n    \n    for down in downsample_pipeline:\n        x = down(x)\n        skips.append(x)\n#         print(\"Downsample layer output shape:\", x.shape)  # Debugging print statement\n\n        \n    skips = reversed(skips[:-1])\n    \n    for up, skip in zip(upsample_pipeline, skips):\n        x = up(x)\n#         print(\"Upsample layer output shape:\", x.shape)  # Debugging print statement\n#         print(\"Skip connection shape:\", skip.shape)     # Debugging print statement\n        x = layers.Concatenate()([x, skip])\n\n    last_layer = layers.Conv2DTranspose(3, (3,3), strides=(2,2), padding=\"same\", kernel_initializer=kernel_initializer, activation=\"tanh\")(x)\n    return tf.keras.Model(inputs=inputs, outputs=last_layer)","metadata":{"execution":{"iopub.status.busy":"2023-12-11T02:36:59.118893Z","iopub.execute_input":"2023-12-11T02:36:59.119269Z","iopub.status.idle":"2023-12-11T02:36:59.133852Z","shell.execute_reply.started":"2023-12-11T02:36:59.119242Z","shell.execute_reply":"2023-12-11T02:36:59.132834Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def Discriminator(n, downsample_parameters:dict, normalize, zeropadding):\n    inputs=layers.Input(shape=[256, 256, 3], name=\"input_image\")\n    x=inputs\n    \n    gamma_initializer=tf.keras.initializers.RandomNormal(0, 0.02)\n    kernel_initializer=tf.random_normal_initializer(0, 0.02)\n    \n    downsample_pipeline = create_downsample_pipeline(n, downsample_parameters, normalize=normalize, zeropadding=zeropadding)\n    \n    for down in downsample_pipeline:\n        x=down(x)\n    \n    zero_pad1 = layers.ZeroPadding2D()(x)\n    conv = layers.Conv2D(512, (3,3), strides=1,kernel_initializer=kernel_initializer,use_bias=False)(zero_pad1)\n    norm1 = tfa.layers.InstanceNormalization(gamma_initializer=gamma_initializer)(conv)\n    leaky_relu = layers.LeakyReLU()(norm1)\n    zero_pad2 = layers.ZeroPadding2D()(leaky_relu)\n    last = layers.Conv2D(1, (3,3), strides=1,kernel_initializer=kernel_initializer)(zero_pad2) \n    return tf.keras.Model(inputs=inputs, outputs=last)\n    \n#     model = Sequential()\n#     model.add(layers.Conv2D(, kernel_size, strides=strides, padding=padding, kernel_initializer=initializer, activation=last_activation))\n#     model.add(tfa.layers.InstanceNormalization(gamma_initializer=gamma_initializer))\n#     if zero_padding:         \n#         model.add(layers.ZeroPadding2D())\n#     model.add(layers.LeakyReLU())\n#     model.add(layers.Conv2D(1, last_kernel_size, last_strides, kernel_initializer=initializer)) \n#     outputs=model()(X3)\n#     return Keras.Model(inputs=inputs, outputs=outputs)\n","metadata":{"execution":{"iopub.status.busy":"2023-12-11T02:36:59.137902Z","iopub.execute_input":"2023-12-11T02:36:59.138172Z","iopub.status.idle":"2023-12-11T02:36:59.148876Z","shell.execute_reply.started":"2023-12-11T02:36:59.138134Z","shell.execute_reply":"2023-12-11T02:36:59.148056Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"generator_layers = 8\ndiscriminator_layers = 8\nn_dropouts = 3\n\nwith strategy.scope():\n    monet_generator = Generator(n=generator_layers, n_dropouts=n_dropouts, downsample_parameters=parameters[\"down\"], upsample_parameters=parameters[\"up\"], normalize=True, zeropadding=False) # transforms photos to Monet-esque paintings\n    photo_generator = Generator(n=generator_layers, n_dropouts=n_dropouts,downsample_parameters=parameters[\"down\"], upsample_parameters=parameters[\"up\"], normalize=True, zeropadding=False) # transforms Monet paintings to be more like photos\n\n    monet_discriminator = Discriminator(n=discriminator_layers, downsample_parameters=parameters[\"down\"], normalize=True, zeropadding=False) # differentiates real Monet paintings and generated Monet paintings\n    photo_discriminator = Discriminator(n=discriminator_layers, downsample_parameters=parameters[\"down\"], normalize=True, zeropadding=False) # differentiates real photos and generated photos\n    \n# 8, 8, 3","metadata":{"execution":{"iopub.status.busy":"2023-12-11T02:36:59.149866Z","iopub.execute_input":"2023-12-11T02:36:59.150118Z","iopub.status.idle":"2023-12-11T02:42:17.704933Z","shell.execute_reply.started":"2023-12-11T02:36:59.150095Z","shell.execute_reply":"2023-12-11T02:42:17.704118Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class CycleGan(keras.Model):\n    def __init__(self,\n        monet_generator,\n        photo_generator,\n        monet_discriminator,\n        photo_discriminator,\n        lambda_cycle=10,\n    ):\n        super(CycleGan, self).__init__()\n        self.m_gen = monet_generator\n        self.p_gen = photo_generator\n        self.m_disc = monet_discriminator\n        self.p_disc = photo_discriminator\n        self.lambda_cycle = lambda_cycle\n        \n    def compile(\n        self,\n        m_gen_optimizer,\n        p_gen_optimizer,\n        m_disc_optimizer,\n        p_disc_optimizer,\n        gen_loss_fn,\n        disc_loss_fn,\n        cycle_loss_fn,\n        identity_loss_fn\n    ):\n        super(CycleGan, self).compile()\n        self.m_gen_optimizer = m_gen_optimizer\n        self.p_gen_optimizer = p_gen_optimizer\n        self.m_disc_optimizer = m_disc_optimizer\n        self.p_disc_optimizer = p_disc_optimizer\n        self.gen_loss_fn = gen_loss_fn\n        self.disc_loss_fn = disc_loss_fn\n        self.cycle_loss_fn = cycle_loss_fn\n        self.identity_loss_fn = identity_loss_fn\n        \n    def train_step(self, batch_data):\n        real_monet, real_photo = batch_data\n        \n        with tf.GradientTape(persistent=True) as tape:\n            # photo to monet back to photo\n            fake_monet = self.m_gen(real_photo, training=True)\n            cycled_photo = self.p_gen(fake_monet, training=True)\n\n            # monet to photo back to monet\n            fake_photo = self.p_gen(real_monet, training=True)\n            cycled_monet = self.m_gen(fake_photo, training=True)\n\n            # generating itself\n            same_monet = self.m_gen(real_monet, training=True)\n            same_photo = self.p_gen(real_photo, training=True)\n            \n\n            # discriminator used to check, inputing real images\n            disc_real_monet = self.m_disc(real_monet, training=True)\n            disc_real_photo = self.p_disc(real_photo, training=True)\n\n            # discriminator used to check, inputing fake images\n            disc_fake_monet = self.m_disc(fake_monet, training=True)\n            disc_fake_photo = self.p_disc(fake_photo, training=True)\n\n            # evaluates generator loss\n            monet_gen_loss = self.gen_loss_fn(disc_fake_monet)\n            photo_gen_loss = self.gen_loss_fn(disc_fake_photo)\n\n            # evaluates total cycle consistency loss\n            total_cycle_loss = self.cycle_loss_fn(real_monet, cycled_monet, self.lambda_cycle) + self.cycle_loss_fn(real_photo, cycled_photo, self.lambda_cycle)\n\n            # evaluates total generator loss\n            total_monet_gen_loss = monet_gen_loss + total_cycle_loss + self.identity_loss_fn(real_monet, same_monet, self.lambda_cycle)\n            total_photo_gen_loss = photo_gen_loss + total_cycle_loss + self.identity_loss_fn(real_photo, same_photo, self.lambda_cycle)\n\n            # evaluates discriminator loss\n            monet_disc_loss = self.disc_loss_fn(disc_real_monet, disc_fake_monet)\n            photo_disc_loss = self.disc_loss_fn(disc_real_photo, disc_fake_photo)\n\n        # Calculate the gradients for generator and discriminator\n        monet_generator_gradients = tape.gradient(total_monet_gen_loss,\n                                                  self.m_gen.trainable_variables)\n        photo_generator_gradients = tape.gradient(total_photo_gen_loss,\n                                                  self.p_gen.trainable_variables)\n\n        monet_discriminator_gradients = tape.gradient(monet_disc_loss,\n                                                      self.m_disc.trainable_variables)\n        photo_discriminator_gradients = tape.gradient(photo_disc_loss,\n                                                      self.p_disc.trainable_variables)\n\n        # Apply the gradients to the optimizer\n        self.m_gen_optimizer.apply_gradients(zip(monet_generator_gradients,\n                                                 self.m_gen.trainable_variables))\n\n        self.p_gen_optimizer.apply_gradients(zip(photo_generator_gradients,\n                                                 self.p_gen.trainable_variables))\n\n        self.m_disc_optimizer.apply_gradients(zip(monet_discriminator_gradients,\n                                                  self.m_disc.trainable_variables))\n\n        self.p_disc_optimizer.apply_gradients(zip(photo_discriminator_gradients,\n                                                  self.p_disc.trainable_variables))\n        \n        return {\n            \"monet_gen_loss\": total_monet_gen_loss,\n            \"photo_gen_loss\": total_photo_gen_loss,\n            \"monet_disc_loss\": monet_disc_loss,\n            \"photo_disc_loss\": photo_disc_loss\n        }","metadata":{"execution":{"iopub.status.busy":"2023-12-11T02:42:17.706260Z","iopub.execute_input":"2023-12-11T02:42:17.706567Z","iopub.status.idle":"2023-12-11T02:42:17.729629Z","shell.execute_reply.started":"2023-12-11T02:42:17.706541Z","shell.execute_reply":"2023-12-11T02:42:17.728299Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"with strategy.scope():\n    def discriminator_loss(real, generated):\n        real_loss = tf.keras.losses.BinaryCrossentropy(from_logits=True, reduction=tf.keras.losses.Reduction.NONE)(tf.ones_like(real), real)\n        generated_loss = tf.keras.losses.BinaryCrossentropy(from_logits=True, reduction=tf.keras.losses.Reduction.NONE)(tf.zeros_like(generated), generated)\n        total_disc_loss = real_loss + generated_loss\n        return total_disc_loss * 0.5\n    \n    \nwith strategy.scope():\n    def generator_loss(generated):\n        return tf.keras.losses.BinaryCrossentropy(from_logits=True, reduction=tf.keras.losses.Reduction.NONE)(tf.ones_like(generated), generated)\n    \n    \nwith strategy.scope():\n    def calc_cycle_loss(real_image, cycled_image, LAMBDA):\n        loss1 = tf.reduce_mean(tf.abs(real_image - cycled_image))\n        return LAMBDA * loss1\n    \n    \nwith strategy.scope():\n    def identity_loss(real_image, same_image, LAMBDA):\n        loss = tf.reduce_mean(tf.abs(real_image - same_image))\n        return LAMBDA * 0.5 * loss\n    \nlr_schedule = keras.optimizers.schedules.ExponentialDecay(\n    initial_learning_rate=2e-4,\n    decay_steps=100000,\n    decay_rate=0.96)    \n\nwith strategy.scope():\n    monet_generator_optimizer = tf.keras.optimizers.Adam(learning_rate=lr_schedule, beta_1=0.5)\n    photo_generator_optimizer = tf.keras.optimizers.Adam(learning_rate=lr_schedule, beta_1=0.5)\n\n    monet_discriminator_optimizer = tf.keras.optimizers.Adam(learning_rate=lr_schedule, beta_1=0.5)\n    photo_discriminator_optimizer = tf.keras.optimizers.Adam(learning_rate=lr_schedule, beta_1=0.5)","metadata":{"execution":{"iopub.status.busy":"2023-12-11T02:42:17.731064Z","iopub.execute_input":"2023-12-11T02:42:17.731474Z","iopub.status.idle":"2023-12-11T02:42:17.778029Z","shell.execute_reply.started":"2023-12-11T02:42:17.731437Z","shell.execute_reply":"2023-12-11T02:42:17.777102Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"with strategy.scope():\n    cycle_gan_model = CycleGan(\n        monet_generator, photo_generator, monet_discriminator, photo_discriminator)\n\n    cycle_gan_model.compile(\n        m_gen_optimizer = monet_generator_optimizer,\n        p_gen_optimizer = photo_generator_optimizer,\n        m_disc_optimizer = monet_discriminator_optimizer,\n        p_disc_optimizer = photo_discriminator_optimizer,\n        gen_loss_fn = generator_loss,\n        disc_loss_fn = discriminator_loss,\n        cycle_loss_fn = calc_cycle_loss,\n        identity_loss_fn = identity_loss)","metadata":{"execution":{"iopub.status.busy":"2023-12-11T02:42:17.779237Z","iopub.execute_input":"2023-12-11T02:42:17.779541Z","iopub.status.idle":"2023-12-11T02:42:17.808135Z","shell.execute_reply.started":"2023-12-11T02:42:17.779515Z","shell.execute_reply":"2023-12-11T02:42:17.807384Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cycle_gan_model.fit(\n    tf.data.Dataset.zip((monet_ds, photo_ds)),\n    epochs=10)","metadata":{"execution":{"iopub.status.busy":"2023-12-11T02:42:17.809253Z","iopub.execute_input":"2023-12-11T02:42:17.809540Z","iopub.status.idle":"2023-12-11T03:05:22.601761Z","shell.execute_reply.started":"2023-12-11T02:42:17.809515Z","shell.execute_reply":"2023-12-11T03:05:22.600710Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"_, ax = plt.subplots(5, 2, figsize=(12, 12))\nfor i, img in enumerate(photo_ds.take(5)):\n    prediction = monet_generator(img, training=False)[0].numpy()\n    prediction = (prediction * 127.5 + 127.5).astype(np.uint8)\n    img = (img[0] * 127.5 + 127.5).numpy().astype(np.uint8)\n\n    ax[i, 0].imshow(img)\n    ax[i, 1].imshow(prediction)\n    ax[i, 0].set_title(\"Input Photo\")\n    ax[i, 1].set_title(\"Monet-esque\")\n    ax[i, 0].axis(\"off\")\n    ax[i, 1].axis(\"off\")\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-12-11T03:05:22.603518Z","iopub.execute_input":"2023-12-11T03:05:22.603952Z","iopub.status.idle":"2023-12-11T03:05:24.098440Z","shell.execute_reply.started":"2023-12-11T03:05:22.603914Z","shell.execute_reply":"2023-12-11T03:05:24.097408Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import os\nimport numpy as np\nimport PIL\n\n! mkdir ../images\ni = 1\nfor img in fast_photo_ds:\n    prediction = monet_generator.predict(img)\n    prediction = (prediction * 127.5 + 127.5).astype(np.uint8)\n    for pred in prediction:\n        im = PIL.Image.fromarray(pred)\n        im.save(\"../images/\" + str(i) + \".jpg\")\n        i += 1\n\nimport shutil\nshutil.make_archive(\"/kaggle/working/images\", 'zip', \"/kaggle/images\")\n","metadata":{"execution":{"iopub.status.busy":"2023-12-11T03:23:46.444083Z","iopub.execute_input":"2023-12-11T03:23:46.445005Z","iopub.status.idle":"2023-12-11T03:31:33.311298Z","shell.execute_reply.started":"2023-12-11T03:23:46.444970Z","shell.execute_reply":"2023-12-11T03:31:33.310300Z"},"_kg_hide-output":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if os.path.exists(\"images.zip\"):\n    print(\"Zip file exists.\")","metadata":{"execution":{"iopub.status.busy":"2023-12-11T03:31:33.320342Z","iopub.execute_input":"2023-12-11T03:31:33.321069Z","iopub.status.idle":"2023-12-11T03:31:33.341092Z","shell.execute_reply.started":"2023-12-11T03:31:33.320991Z","shell.execute_reply":"2023-12-11T03:31:33.340214Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Conclusion\n\nIn conclusion this was the most difficult project for me as I am not familiar with CycleGAN and had to learn a lot about the architecture. I am not happy with my results but due to the time constraints I cannot iterate any further on this project. It seems that GANs or at least CycleGAN is extremely sensitive. Slight changes to the architecture drastically affected the results (such as +/- 1 Dropout layer). \n\nI am super interested in GANs after this project and will definitely continue to learn more in this space.","metadata":{}},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}